---
layout: post
title: Milestone 2
toc: true
---

## Ingénierie des caractéristiques I

### Nombre de buts selon la distance au filet

Le graphique suivant nous montre le nombre de buts marqués selon la distance au filet avec une
distinction entre les buts marqués avec filets vides et les buts marqués avec les filets non-vides:

![Buts selon la distance au filet](/public/goals_by_distance_milestone2.png)

Sur la base de ce graphique, on a fait les remarques suivantes :

- dans le cas où les filets ne sont pas vides, plus on s'éloigne du filet moins il y a de buts.
  Autrement dit, la majorité des buts nets non vides sont marqués proche du filet. Cela fait du sens vu que
  quand on est proche du filet, un tir a moins de chance d'être bloqué ou arrêté par le gardien.
- dans le cas où les filets sont vides, il n'y a que très peu de buts qui sont marqués peu importe que l'on soit proche
  ou loin des filets.
  Cela s'explique par le fait que les équipes ne peuvent se passer de leur
  gardien
  qu'à des moments particuliers.
  Par exemple, si une équipe perd par un ou deux buts en fin de match,
  elle peut retirer son gardien pour ajouter un joueur de patinage supplémentaire.

Vu la rareté des buts nets non vides marqués de loin, il était naturel qu'on regarde ces évènements plus en profondeur.
Tout d'abord, on a observé qu'il y avait **118 buts** nets non vides marqués l'intérieur de la zone défensive (à une
distance plus grande que 90 pieds)
Parmi ces évènements, on a remarqué que certains d'entre eux avaient des informations erronées.
Par exemple, dans le cadre du match opposant les New-York Rangers aux Toronto Maple Leafs qui s'est joué le **23 février
2017**, le but
marqué par Mats Zuccarello durant la période de shoot-out a été marqué du côté droit de la patinoire (voir la
vidéo [ici](https://www.youtube.com/watch?v=lM6JXVW0-YY)). Cependant,
dans les données qu'on a récupérées sur le site de la NHL, l'évènement est enrégistré comme ayant eu lieu du côté gauche
de la patinoire (à la position **(-71,5)**). Cela explique
pourquoi la distance par rapport au filet pour cet évènement était anormalement grande.

Aussi, on a analysé les données de tous les buts marqués depuis l'intérieur de la zone défensive, peu importe que les
filets soient
vides ou pas. On a identifié d'autres évènements dont le type de tir était incorrect.
Par exemple, dans le cadre du match opposant les Pittsburgh Penguins aux St. Louis Blues qui s'est joué le **4 février
2017**,
Sidney Crosby a marqué un but de type **wrist** durant la 3ième période du match depuis le centre de la patinoire (voir
la vidéo [ici](https://www.youtube.com/watch?v=CHcbWHyRDbE)). Cependant,
dans les données qu'on a récupérées sur le site de la NHL, le but est enrégistré comme étant de type **wrap-around**, ce
qui est impossible, car un tir de type **wrap-around** est toujours proche des filets.

## Ingénierie des caractéristiques II

Dans cette section, nous allons voir de nouvelles d'ajouter des caractéristiques pertinentes pour améliorer notre modèle
de
prédiction.
Certaines caractéristiques ont simplement été adaptées par rapport au Milestone 1.

#### 1. Caractéristiques de base

- Secondes de jeu (gameSeconds) : nombre total de secondes écoulées dans le match (prenant en compte la période du
  match)
- Période de jeu (periodNumber) : période en cours du match.
- Coordonnées x (xCoord) : abscisse de l'action par rapport au centre du terrain (ordonnée à l'origine)
- Coordonnées y (yCoord) : ordonnées de l'action par rapport au centre (ordonnée à l'origine)
- Distance de tir (shotDistance) : distance euclidienne (en pieds) du tir par rapport au filet.
  Pour cela, prendre en compte la période et le côté de l'équipe
- Angle de tir (shotAngle) : angle du tir (de 0 à 90°) par rapport au filet.
- Type de tir (shotType) : type de tir utilisé (slap, wrist, etc...).

#### 2. Caractéristiques des évènements précédents

- Dernier type d'évènement (previousEventType) : type d'évènement ayant précédé le tir (blocked-shot, stoppage, etc...).
- Coordonnées x précédente (previousXCoord) : coordonnée x du dernier évènement (manquant s'il s'agit d'un stoppage)
- Coordonnées y précédente (previousYCoord) : coordonnée y du dernier évènement (manquant s'il s'agit d'un stoppage)
- Temps depuis le dernier évènement (timeSinceLastEvent) : intervalle de temps entre l'évènement précédent et le tir.
- Distance depuis le dernier évènement (distanceFromLastEvent) : distance euclidienne (en pieds) parcourue depuis
  l'évènement précédent.
- Rebond (rebound) : Indique si le tir est un rebond à la condition qu'il précède d'un tir (évènement : shot-on-goal)
- Changement d'angle de tir (reboundAngleShot) : calcule de l'angle entre le tir précédent et le tir actuel (si et
  seulement le tir est un rebond).
- Vitesse depuis le dernier évènement (speedFromLastEvent) : distance depuis le dernier évènement (en pieds) divisé par
  le temps écoulé (en
  sec)

## Modèles avancés

On a également éssayé le modèle XGBoost. Voila les résultats obtenus avec trois configurations différentes
de ce type de modèle:

![](/public/modele_avance_q3_roc.png)

![](/public/modele_avance_q3_goal_rate.png)

![](/public/modele_avance_q3_cumulative_goal_proportion.png)

![](/public/modele_avance_q3_reliability_diagram.png)

Comme suit, on va expliquer chacune des trois configurations.

### Modèle XGBoost de base

Ici, on voulait obtenir un résultat de base avec le modèle de type XGBoost.
On a donc divisé nos données en deux ensembles: un ensemble d'entrainement ayant **80%** des données et un ensemble de validation ayant **20%** des données.
Cette répartition a été faite tout en préservant les proportions des catégories dans chaque ensemble.
Autrement dit, pour chacun de ces deux ensembles, on avait toujours environ **10%** des données qui sont des buts et **90%** des données qui ne le sont pas.
Le modèle a été entrainé sur l'ensemble d'entrainement avec les valeurs d'hyper-paramètres
par défaut et a été évalué sur l'ensemble de validation pour obtenir les résultats des courbes précédentes.
De plus, seulement la distance et l'angle ont été utilisés comme variables explicatives.

Il est naturel de comparer ce modèle au modèle de régression logistique (entrainé en utilisant uniquement la distance et l'angle) obtenu précédement.
Tout d'abord, les deux modèles ont un AUC similaire (autour de **0.71**).
Leurs courbes de taux de buts en fonction du percentile de probabilité sont similaires. En effet, elles croissent de la même manière quand le percentile
augmente. Ca démontre que les probabilités prédites par les deux modèles sont assez cohérentes avec les fréquences observées.

<!-- Ajouter comment courbe cumulative -->

La courbe de calibration du modèle xgboost est cohérente au début
mais devient incohérente aux extrémités et décroit, ce qui met en évidende la tendance du modèle à sur-prédire.
La courbe de calibration du modèle logistique met plutot en évidence une tendance à sous-prédire.
Cependant, il y'a des chances que ces tendance de sur et de sous-prédictions ne soient pas éffective, notament dans les cas
ou il n'y a pas assez de données dans ces intervalles(bins) de sur ou de sous-prédictions.

<!-- Ajouter lien expérience wandb -->

### Modèle XGBoost avec de nouvelles caractéristiques

Ici, on a entrainé le modèle XGBoost en utilisant 15 variables explicatives au total dont **la distance, l'angle, les coordonées,
la période, le type de tir** et autres.
Pour trouver les hyper-paramètres optimaux de ce modèle, on a utilisé la recherche par grille avec une validation croisée. On s'est
focalisé sur les hyper-paramètres suivants : le taux d'apprentissage, la profondeur maximale des arbres, le nombre d'arbres
et la proportion des échantillons utilisés par chaque arbre. La combinaison d'hyper-paramètre qu'on a choisie est celle qui minimisait l'**érreur de calibration attendue** ou encore
qui maximisait l'**érreur de calibration attendue négative**. Le graphique suivant donne un apercu de nos expérimentations:

![](/public/modele_avance_q2_grid_search_hyperparameter_new.png)

C'est donc la 16ième combinaison d'hyperparamètres qu'on a choisie pour notre modèle.
Concernant les résultats du modèle, on voit dans les graphiques qu'il a un meilleur AUC que le modèle XGBoost de base, tout en restant assez bien calibré.

<!-- Ajouter lien expérience wandb -->

### Modèle XGBoost avec des caractéristiques sélectionnées

Ici, on a procédé à une sélection des caractéristiques utlisées par le modèle précédent.
On a fait cette sélection en utilisant l'importance des caractéristiques dans la construction d'une forêt aléatoire à partir des données.
Les importances des 15 caractéristiques variaient entre **0.0005** et **0.1**. Il fallait définir un seuil tel que les variables avec une importance plus basse que ce seuil
seraient rétirées de l'ensemble. Le graphique suivant donne un apercu de l'érreur de calibration attendue qu'on a obtenue (par validation croisée) pour les différents seuils testés:

![](/public/modele_avance_q3_feature_selection_random_forest.png)

C'est donc le seuil **0.0815** qu'on a utilisé pour notre sélection de caractéristique vu qu'il nous a donné l'érreur la plus basse.
Avec ce seuil, 8 variables explicatives sur les 15 initiales ont été conservées.
On remarque sur les graphiques que malgré cette diminution de pres de moitié du nombre de caractéristiques, l'AUC du modèle obtenu (**0.75**) reste encore bien supérieur
à celui du modèle XGBoost de base (**0.71**). De plus, ce nouveau modèle est toujours bien calibré.

<!-- Ajouter lien expérience wandb -->

## Faites de votre mieux

Nous avons commencé par utiliser des réseaux de neurones Perceptron et multicouches (MLP) pour évaluer différentes
architectures. Le
modèle de base (`Perceptron`) nous a servi de point de départ pour nos expérimentations. Ensuite, nous avons introduit
des modèles plus complexes (`MLP_H1` et `MLP_H2`), avec une et deux couches cachées. Cela permettait de capturer les interactions entre les caractéristiques

### Optimisation des hyper-paramètres

Pour optimiser les performances de nos modèles, nous avons utilisé **Optuna** pour une optimisation bayésienne des
hyper-paramètres.

Nous avons pu optimiser les résultats dans les plages suivantes :

- La **taille des batches** dans une plage de 32 à 256.
- Le **taux d'apprentissage**, : taux d'apprentissage logarithmique entre (10⁻⁵) et (10⁻¹).
- Le **poids de régularisation** : contrôler la complexité des modèles et éviter l'overfitting
- Le **minority_weight** : compenser le déséquilibre des classes dans les données de hockey, où les
  buts sont relativement rares par rapport aux tirs totaux.

### Exploration des Métriques de Performance

L'accuracy peut être trompeuse dans le cas de classes déséquilibrées comme les tirs au but.
Ainsi, nous avons préféré utiliser le F1-score, qui met en balance la précision et le rappel,
offrant une évaluation plus précise de notre capacité à identifier les buts tout en limitant les faux positifs et les
faux négatifs.

### Division des Données


### Visualisations des Performances

- **Courbes ROC/AUC**:
-
- **Taux de But par Centile de Probabilité** :

- **Proportion Cumulée de Buts** :

- **Courbe de Fiabilité** :
